{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Image Recognition\n",
    "** --- Compression & Discrimination by PCA, AutoEncoder, FLD**\n",
    "\n",
    "**Jiayu WU | 905054229**\n",
    "\n",
    "This project aims to explore face recognition by extracting effective compression and representations of face images. \n",
    "\n",
    "Firstly, we start with the classical principal component analysis for dimension reduction and generation from the latent components. In order to address different aspects of the images - face apperance and photographing angles, we decompose the two aspects by image alignment by warping according to landmarks. \n",
    "\n",
    "In addition, we generalize linear projection of PCA onto latent space to a more flexible nonlinear projection learned by neural network, which is AutoEncoder, a effective way to compress high dimensional, sparse data. \n",
    "\n",
    "At last, we explore Fisher Linear Discriminant, a discriminative method by linear projection that tells apart female and male faces.\n",
    "\n",
    "We experiemnt with a dataset of 1000 face imgaes with 256 x 256 pixels, pre-processed such that the background and hair are removed and the faces have similar lighting. Each face has 68 landmarks manually identified. The dataset is split into training/testing set with testing size of 200.\n",
    "\n",
    "## 1. PCA - dimension reduction\n",
    "\n",
    "### 1.1 PCA on Raw Image \n",
    "\n",
    "As PCA is usually applied on the intensity, in our experiment the color image is converted to the HSV and PCA is applied on the Value channel.\n",
    "\n",
    "Applying PCA on the 800 training examples by SVD decomposition, we obtain eigen faces sorted by 'importance' or 'amount of infomation' - the total variance explained. The First 20 faces are displayed in Fig.1-1-1. \n",
    "<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_1_1.png\"> \n",
    "\n",
    "Although the raw image data (V channel) is in a very high-dim space of $N^2=128 \\times 128$, we show that the image can be reconstructed to high resemblence to the original using only the first 50 eigen faces, as diplayed in Fig.1-1-2 using 20 testing images. We also compare the reconstrution errors (average MSE normalized by pixel)on the 200 testing images with different numbers of eigenfaces in Fig.1-1-3.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_1_2.png\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_1_3.png\" style=\"width:500px;height:360px;\"> \n",
    "\n",
    "It can be observed that, the err decrease more and more slowly as the number eigenfaces used in reconstruction increase, and it diminish to less than $.005$ with only 50 eigenfaces (the raw data dimenionality is 300 times higher). It can be concluded that high-dim, sparse data like image pixels can be effectively compressed to a lower space for modeling.\n",
    "\n",
    "\n",
    "### 1.2. PCA on landmarks for warping\n",
    "\n",
    "Since in the image the faces have different angles, it is very reasonable to align (image warping) them to a mean position before extracting appearance components. It is notable that the identified landmarks can also be reconstructed by PCA, such that we deal with a lower space than the original ($68\\time 2$).\n",
    "\n",
    "The eigen landmarks and resonstruction errors are ploted in Fig.1-2-1 and Fig.1-2-2 respectively. The error here is defined as the distance on the 2-dim plane. A sharp drop in error can be observed within the first 10 eigen lanmarks, therefore we believe 10 eigen warping will be good enough.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_2_1.png\"> |\n",
    "<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_2_2.png\" style=\"width:500px;height:360px;\">\n",
    "\n",
    "### 1.2. PCA with landmarks alignment\n",
    "\n",
    "| - | - | - |\n",
    "|----|----|----|\n",
    "|<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_1_3.png\" style=\"width:370px;height:350px;\">|<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_1_2.png\" style=\"width:370px;height:350px;\">|<img src=\"https://raw.githubusercontent.com/Alice86/DeepLearning/master/231_1_PCA_Autoencoder_FLD_color_faces/fig/Fig1_2_2.png\" style=\"width:370px;height:350px;\">|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AutoEncoder  - nonlinear generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FLD - discrimination by linear projection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
